{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.unzip dataset"
   ],
   "metadata": {
    "id": "68bwQOUvJXQo",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qqb-Y99ZmW_p",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "25efbcd8-9a34-4c5a-a664-3ff48a206dd0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "unzip:  cannot find or open /content/Flowers-Dataset.zip, /content/Flowers-Dataset.zip.zip or /content/Flowers-Dataset.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip '/content/Flowers-Dataset.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing necessary Libraries"
   ],
   "metadata": {
    "id": "6BcqUaVY7qm_",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "id": "YDOBjJ7h7qAz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Dropout,Conv2D,Flatten,MaxPool2D,Reshape,InputLayer\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img,img_to_array\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ],
   "metadata": {
    "id": "s8BuWCFH9LOd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2.Image Augmentation"
   ],
   "metadata": {
    "id": "YXsfv1hI9rXU",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path = 'flowers/'"
   ],
   "metadata": {
    "id": "Ni-v3Rek9PJ1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_data_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                             shear_range = 0.2,\n",
    "                             zoom_range = 0.2,\n",
    "                             horizontal_flip = True,\n",
    "                             validation_split = 0.30)\n",
    "test_data_gen = ImageDataGenerator(rescale = 1./255,validation_split = 0.30)"
   ],
   "metadata": {
    "id": "xDKm1OyW96QZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "training_set = train_data_gen.flow_from_directory(path,\n",
    "                                                 target_size=(64,64),\n",
    "                                                 batch_size=100,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 subset = 'training')\n",
    "\n",
    "testing_set = test_data_gen.flow_from_directory(path,\n",
    "                                                 target_size=(64,64),\n",
    "                                                 batch_size=100,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True,\n",
    "                                                 color_mode='rgb',\n",
    "                                                 subset = 'validation')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "g-orOH3O9-6S",
    "outputId": "0ca91a4d-fb2c-429e-b5c2-8e99b2eedb51",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-e2761740de73>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m                                                  \u001B[0mshuffle\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m                                                  \u001B[0mcolor_mode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'rgb'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m                                                  subset = 'training')\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m testing_set = test_data_gen.flow_from_directory(path,\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36mflow_from_directory\u001B[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001B[0m\n\u001B[1;32m    990\u001B[0m         \u001B[0mfollow_links\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfollow_links\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    991\u001B[0m         \u001B[0msubset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 992\u001B[0;31m         interpolation=interpolation)\n\u001B[0m\u001B[1;32m    993\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    994\u001B[0m   def flow_from_dataframe(self,\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[1;32m    408\u001B[0m         \u001B[0msubset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msubset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m         \u001B[0minterpolation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minterpolation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 410\u001B[0;31m         **kwargs)\n\u001B[0m\u001B[1;32m    411\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    412\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001B[0m\n\u001B[1;32m    113\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mclasses\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    114\u001B[0m             \u001B[0mclasses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 115\u001B[0;31m             \u001B[0;32mfor\u001B[0m \u001B[0msubdir\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msorted\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    116\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirectory\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubdir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    117\u001B[0m                     \u001B[0mclasses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msubdir\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'flowers/'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3.Create Model\n"
   ],
   "metadata": {
    "id": "KKwtMwL5-pmX",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model = Sequential()"
   ],
   "metadata": {
    "id": "lJDHOcPRCgZP",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4.Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)"
   ],
   "metadata": {
    "id": "x98mK3QBCkO-",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#convolution and Pooling layer 1\n",
    "model.add(Conv2D(filters=48,kernel_size=3,activation='relu',input_shape=(64,64,3)))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#convolution and Pooling layer 2\n",
    "model.add(Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#Flattening the images\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully Connected layers\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5,activation='softmax'))"
   ],
   "metadata": {
    "id": "TLwmQtSzCjCL",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "id": "sMZYxR0mC3Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5.Compile The Model\n"
   ],
   "metadata": {
    "id": "bLnwrK-2DSPN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "wDDyYvVbDG9g",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6.Fit The Model"
   ],
   "metadata": {
    "id": "5foUuqvRDyF6",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "early_stop = EarlyStopping(monitor='val_accuracy', \n",
    "                           patience=5,verbose=1,mode='auto')\n",
    "\n",
    "lr = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                       factor=0.2,patience=5, \n",
    "                       min_lr=0.00001)\n",
    "\n",
    "callback = [early_stop,lr]"
   ],
   "metadata": {
    "id": "PJN4GHwKDpBu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Model"
   ],
   "metadata": {
    "id": "yJsbxf-NEIgw",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "result = model.fit(x=training_set, validation_data=testing_set, epochs=50)"
   ],
   "metadata": {
    "id": "1A2ILadkD87l",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss and Accuracy check using plot"
   ],
   "metadata": {
    "id": "QDiAF_S8G-d7",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#plot the loss\n",
    "plt.plot(result.history['loss'], label='train loss')\n",
    "plt.plot(result.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(result.history['accuracy'], label='train acc')\n",
    "plt.plot(result.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "wVteR5g5EMvB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7.Save the Model"
   ],
   "metadata": {
    "id": "XbQ7RpmPHI3N",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('flower.h5')"
   ],
   "metadata": {
    "id": "lF8o8sQUHDhv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8.Test The Model"
   ],
   "metadata": {
    "id": "Mx0H-7mOHdBN",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "training_set.class_indices"
   ],
   "metadata": {
    "id": "j4Ga-GPjI3EW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "classes = ['Daisy','Dandelion','Rose','Sunflower','Tulip'] \n",
    "def testing(img):\n",
    "    img = image.load_img(img,target_size=(64,64)) \n",
    "    x = image.img_to_array(img) \n",
    "    x = np.expand_dims(x,axis=0) \n",
    "    pred = np.argmax(model.predict(x)) \n",
    "    return print(\"Predicted class as:\",classes[pred])\n",
    "\n",
    "def img_show(img):\n",
    "    img1 = image.load_img(img,target_size=(64,64)) \n",
    "    plt.imshow(img1)"
   ],
   "metadata": {
    "id": "PaTWtDVrL-kp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test1\n",
    "img_show('/content/flowers/daisy/25360380_1a881a5648.jpg')\n",
    "testing('/content/flowers/daisy/25360380_1a881a5648.jpg')"
   ],
   "metadata": {
    "id": "e0CNyj3nMBr2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test2\n",
    "img_show('/content/flowers/dandelion/461632542_0387557eff.jpg')\n",
    "testing('/content/flowers/dandelion/461632542_0387557eff.jpg')"
   ],
   "metadata": {
    "id": "fkru8DsINPqp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test3\n",
    "img_show('/content/flowers/rose/3753920123_c7ebc18ee3.jpg')\n",
    "testing('/content/flowers/rose/3753920123_c7ebc18ee3.jpg')"
   ],
   "metadata": {
    "id": "TUDAN5sqNta5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test4\n",
    "img_show('/content/flowers/sunflower/164670455_29d8e02bbd_n.jpg')\n",
    "testing('/content/flowers/sunflower/164670455_29d8e02bbd_n.jpg')"
   ],
   "metadata": {
    "id": "DhrLw5CrOIfk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#test5\n",
    "img_show('/content/flowers/tulip/3238068295_b2a7b17f48_n.jpg')\n",
    "testing('/content/flowers/tulip/3238068295_b2a7b17f48_n.jpg')"
   ],
   "metadata": {
    "id": "LxRhz-7uOivl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}